{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from skimage import io\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from scipy.spatial.distance import hamming, cosine\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# import keras library\n",
    "import keras\n",
    "\n",
    "# import Sequential from the keras models module\n",
    "from keras import Sequential\n",
    "\n",
    "# import Dense, Dropout, Flatten, Conv2D, MaxPooling2D from the keras layers module\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def image_loader(image_path, image_size):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, image_size, cv2.INTER_CUBIC)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dataset_preprocessing(dataset_path, labels_file_path, image_size, image_paths_pickle):\n",
    "    with open(labels_file_path, \"r\") as f:\n",
    "        classes = f.read().split(\"\\n\")\n",
    "       \n",
    "    images = []\n",
    "    labels = []\n",
    "    image_paths = []\n",
    "    print(classes)\n",
    "    \n",
    "    for image_name in os.listdir(dataset_path):\n",
    "        try:\n",
    "            image_path = os.path.join(dataset_path, image_name)\n",
    "            images.append(image_loader(image_path, image_size))\n",
    "            image_paths.append(image_path)\n",
    "            \n",
    "            for idx in range(len(classes)):\n",
    "                if classes[idx] in image_name:\n",
    "                    labels.append(idx)\n",
    "                    break\n",
    "                elif len(classes) == idx:\n",
    "                    labels.append(len(classes))\n",
    "                    break\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    with open(image_paths_pickle + \".pickle\", \"wb\") as f:\n",
    "        pickle.dump(image_paths, f)\n",
    "    \n",
    "   # assert len(images) == len(labels)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_path = \"JPEGImages/\"\n",
    "label_path = \"labels.txt\"\n",
    "image_size = (120,72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bus', 'bicycle', 'car', 'motorbike', 'pedestrian', 'trafficlight', 'trafficsignal', '']\n"
     ]
    }
   ],
   "source": [
    "X, y = dataset_preprocessing(dataset_path, label_path, image_size, \"test_image_pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106920, 72, 120, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106920,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\Vinos\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Users\\Vinos\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set model constants\n",
    "num_classes = 1\n",
    "\n",
    "# define model as Sequential\n",
    "model = Sequential()\n",
    "\n",
    "# first convolutional layer with 32 filters\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(72, 120, 3)))\n",
    "\n",
    "# add a second 2D convolutional layer with 64 filters\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\Vinos\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Users\\Vinos\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Users\\Vinos\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Users\\Vinos\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 70, 118, 32)       896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 68, 116, 64)       18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 34, 58, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 114688)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               14680192  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 14,736,641\n",
      "Trainable params: 14,736,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# reduce dimensionality through max pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# third convolutional layer with 64 filters\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "# add dropout to prevent over fitting\n",
    "model.add(Dropout(0.25))\n",
    "# necessary flatten step preceeding dense layer\n",
    "model.add(Flatten())\n",
    "# fully connected layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# add additional dropout to prevent overfitting\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# prediction layers\n",
    "model.add(Dense(num_classes, activation='sigmoid', name='preds'))\n",
    "\n",
    "# show model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    # set the loss as binary_crossentropy\n",
    "    loss='binary_crossentropy',\n",
    "    # set the optimizer as stochastic gradient descent\n",
    "    optimizer=keras.optimizers.SGD(lr=0.001),\n",
    "    # set the metric as accuracy\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# mock-train the model using the first ten observations of the train and test sets\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=5,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 44.70917298773278\n",
      "Test accuracy: 0.539356528247647\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on test set\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
